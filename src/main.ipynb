{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from TwitterEventDetector import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Started at:',time.ctime())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_tweet_dir = '../data/original_tweets/' # end with '/'\n",
    "clean_tweet_dir = '../data/cleaned_tweets/without_retweets/' # end with '/'\n",
    "subwindow_dir = '../data/cleaned_tweets/without_retweets/2012-10-12/' # each file is a subwindow in this folder\n",
    "event_output_dir = '../Results/'\n",
    "wiki_titles_file='../data/enwiki-titles-unstemmed.txt'\n",
    "seg_prob_file='../data/seg_prob_2012_Oct_11-22.json'\n",
    "common_words_file = '../data/common_words.txt'\n",
    "\n",
    "# prepocessing\n",
    "remove_stopwords=True\n",
    "remove_retweets=True\n",
    "\n",
    "# segmentation\n",
    "max_segment_length=4\n",
    "hashtag_wt=3\n",
    "entities_only = False\n",
    "\n",
    "# bursty segment extraction\n",
    "default_seg_prob=0.0000001\n",
    "use_retweet_count=True\n",
    "use_followers_count=True\n",
    "\n",
    "# clustering\n",
    "n_neighbors=4\n",
    "min_cluster_segments=6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = set() # words to be removed while segmenting\n",
    "\n",
    "f = open(common_words_file, 'r')\n",
    "while True:\n",
    "    line = f.readline()\n",
    "    if line == '': break\n",
    "    common_words.add(line.replace('\\n',''))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted = TwitterEventDetector(wiki_titles_file, seg_prob_file, remove_stopwords,remove_retweets, max_segment_length,\n",
    "                           hashtag_wt, use_retweet_count, use_followers_count, default_seg_prob, common_words, entities_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ted.clean_tweets_in_directory(original_tweet_dir, clean_tweet_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment tweets and create TimeWindow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Reading SubWindows')\n",
    "\n",
    "subwindow_files = [f.name for f in os.scandir(subwindow_dir) if f.is_file()]\n",
    "\n",
    "subwindows = []\n",
    "for subwindow_name in subwindow_files[1:4]: # read given subwindows\n",
    "    print('SubWindow:',subwindow_name)\n",
    "    sw = ted.read_subwindow(subwindow_dir + subwindow_name)\n",
    "    subwindows.append(sw)\n",
    "\n",
    "print('Done')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw = TimeWindow(subwindows)\n",
    "print(tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next_subwindow = ted.read_subwindow(subwindow_dir + subwindow_files[4])\n",
    "#tw.advance_window(next_subwindow)\n",
    "#print(tw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bursty Segment Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bursty_segment_weights = ted.bse.get_bursty_segments(tw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Bursty Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seg_sim = get_seg_similarity(bursty_segment_weights, tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "events = get_events(bursty_segment_weights, seg_sim, n_neighbors, min_cluster_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Events to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# event_output_dir += time.ctime().replace(':','-') + '/' # unique output directory each time\n",
    "# os.mkdir(event_output_dir)\n",
    "\n",
    "# event_no = 0\n",
    "# for e,avg_score in events:\n",
    "#     event_no += 1\n",
    "#     print('\\nEVENT:', event_no, ' Avg Bursty Score:', avg_score) \n",
    "#     f = open(event_output_dir + str(event_no) + '.txt', 'w')\n",
    "#     f.write(str(avg_score)+' '+str(e)+'\\n')\n",
    "#     for seg_name in e:\n",
    "#         print(seg_name) \n",
    "#         f.write('SEGMENT:' + seg_name+'\\n')\n",
    "#         for text in set(tw.get_tweets_containing_segment(seg_name)):\n",
    "#             f.write(text+'\\n')\n",
    "#         f.write('\\n')\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Ended at:',time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n_neighbors,min_cluster_segments in [(2,5), (3,8), (4,10)]:\n",
    "    print('No. of Neighbors', n_neighbors)\n",
    "    print('Min Cluster Segments', min_cluster_segments)\n",
    "    events = get_events(bursty_segment_weights, seg_sim, n_neighbors, min_cluster_segments)\n",
    "    event_no = 0\n",
    "    for e,avg_score in events:\n",
    "        event_no += 1\n",
    "        print(event_no, e)\n",
    "    print('-----------------------------------------------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
