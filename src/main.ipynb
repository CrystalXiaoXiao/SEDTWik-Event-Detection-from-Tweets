{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from TwitterEventDetector import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Started at:',time.ctime())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_tweet_dir = '../data/original_tweets/' # end with '/'\n",
    "clean_tweet_dir = '../data/cleaned_tweets/without_retweets/' # end with '/'\n",
    "subwindow_dir = '../data/cleaned_tweets/without_retweets/2012-10-12/' # each file is a subwindow in this folder\n",
    "event_output_dir = '../Results/'\n",
    "wiki_titles_file='../data/enwiki-titles-unstemmed.txt'\n",
    "seg_prob_file='../data/seg_prob_2012_Oct_11-22.json'\n",
    "wiki_Qs_file='../data/WikiQsEng_non_zero_processed.json'\n",
    "\n",
    "# Tweet Cleaning (preprocessing)\n",
    "remove_retweets=True\n",
    "\n",
    "# segmentation\n",
    "max_segment_length=4\n",
    "hashtag_wt=3\n",
    "entities_only = False # if True, then use only hashtags and name_mentions\n",
    "\n",
    "# bursty segment extraction\n",
    "default_seg_prob=0.0000001 # if seg prob not found in file\n",
    "use_retweet_count=True\n",
    "use_followers_count=True\n",
    "\n",
    "# clustering\n",
    "n_neighbors=4\n",
    "threshold=4 # for news_worthiness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ted = TwitterEventDetector(wiki_titles_file, seg_prob_file, wiki_Qs_file, remove_retweets, max_segment_length,\n",
    "                           hashtag_wt, use_retweet_count, use_followers_count, default_seg_prob, entities_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ted.clean_tweets_in_directory(original_tweet_dir, clean_tweet_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment tweets and create TimeWindow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Reading SubWindows')\n",
    "\n",
    "subwindow_files = [f.name for f in os.scandir(subwindow_dir) if f.is_file()]\n",
    "\n",
    "subwindows = []\n",
    "for subwindow_name in subwindow_files[1:4]: # read given subwindows\n",
    "    print('SubWindow:',subwindow_name)\n",
    "    sw = ted.read_subwindow(subwindow_dir + subwindow_name)\n",
    "    subwindows.append(sw)\n",
    "\n",
    "print('Done')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw = TimeWindow(subwindows)\n",
    "print(tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next_subwindow = ted.read_subwindow(subwindow_dir + subwindow_files[4])\n",
    "#tw.advance_window(next_subwindow)\n",
    "#print(tw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bursty Segment Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bursty_segment_weights, segment_newsworthiness = ted.bse.get_bursty_segments(tw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Bursty Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seg_sim = get_seg_similarity(bursty_segment_weights, tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "events = get_events(bursty_segment_weights, segment_newsworthiness, seg_sim, n_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Events to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# output_dir = event_output_dir + time.ctime().replace(':','-') + '/' # unique output directory each time\n",
    "# os.mkdir(output_dir)\n",
    "\n",
    "# event_no = 0\n",
    "# for e,event_worthiness in events:\n",
    "#     event_no += 1\n",
    "#     print('\\nEVENT:', event_no, 'News Worthiness:', event_worthiness) \n",
    "#     f = open(output_dir + str(event_no) + '.txt', 'w')\n",
    "#     f.write(str(e)+' '+str(event_worthiness)+'\\n\\n')\n",
    "#     for seg_name in e:\n",
    "#         print(seg_name) \n",
    "#         f.write('SEGMENT:' + seg_name+'\\n')\n",
    "#         for text in set(tw.get_tweets_containing_segment(seg_name)):\n",
    "#             f.write(text+'\\n')\n",
    "#         f.write('-----------------------------------------------------------\\n')\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Ended at:',time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n_neighbors in [3,4,5]:\n",
    "    print('No. of Neighbors', n_neighbors)\n",
    "    events = get_events(bursty_segment_weights, segment_newsworthiness, seg_sim, n_neighbors)\n",
    "    event_no = 0\n",
    "    for e,event_worthiness in events:\n",
    "        event_no += 1\n",
    "        print(event_no, event_worthiness, e)\n",
    "    print('-----------------------------------------------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
